{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook requires that the data and the model definition is placed in a shared filesystem on the server.\n",
    "### For example if your shared FS is mounted at /shared you could do it like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to the system and execute the following:\n",
    "\n",
    "```\n",
    "[root@p621-met1 shared]# cd /shared\n",
    "/shared\n",
    "[root@p621-met1 shared]# yum install unzip -y\n",
    "[root@p621-met1 shared]# wget https://github.com/mgiessing/WMLA/raw/master/CIFAR10-images.zip\n",
    "[root@p621-met1 shared]# unzip CIFAR10-images.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "[root@p621-met1 shared]# wget https://github.com/mgiessing/WMLA/raw/master/pytorch_resnet.zip\n",
    "[root@p621-met1 shared]# unzip pytorch_resnet.zip\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#Construct API call\n",
    "\n",
    "### *** USER INPUT TO THE FOLLOWING VARIABLES *** ###\n",
    "\n",
    "master_host = 'p621-kvm1.p621.cecc.ihost.com' # REQUIRED: Adjust to your host\n",
    "\n",
    "dli_rest_port = '9243'  #Deep Learning Impact Rest API Port\n",
    "sc_rest_port = '8643' #Conductor Rest API Port\n",
    "\n",
    "#Following config assumes SSL enabled and default ports\n",
    "sc_rest_url = 'https://'+master_host+':'+sc_rest_port+'/platform/rest/conductor/v1'\n",
    "dl_rest_url = 'https://'+master_host+':'+dli_rest_port+'/platform/rest/deeplearning/v1'\n",
    "\n",
    "# User login details\n",
    "wmla_user = 'Admin'\n",
    "wmla_pwd = 'Admin'\n",
    "\n",
    "# Instance Group to be used\n",
    "sig_name =  'ig-dli' \n",
    "\n",
    "dsname = 'CIFAR-10-MG' # Choose anything meaningful, e.g. replace MG with your credentials\n",
    "modelname = \"resnet-18\" # Choose anything meaningful or let as-is (since the model is resnet-18...)\n",
    "\n",
    "#KEEP IN MIND THE FOLLOWING MUST BE ON SHARED FILESYSTEM, in my case it is mounted at /shared\n",
    "trainpath = '/shared/CIFAR-10-images/train' # Path where you uploaded the (train)data \n",
    "modelpath = '/shared/resnet' # Path where you uploaded the model definition\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "\n",
    "myauth = (wmla_user, wmla_pwd)\n",
    "\n",
    "# REST call variables\n",
    "headers = {'Accept': 'application/json'}\n",
    "print (sc_rest_url)\n",
    "print (dl_rest_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial configuration for creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigid(sig_name):\n",
    "    r = requests.get(dl_rest_url + '/scheduler/instances', auth=myauth, verify=False, headers=headers)\n",
    "    res = json.loads(r.text)\n",
    "    for item in res:\n",
    "        if item['name'] == sig_name:\n",
    "            print(\"Found the sigid of {} which is {}\".format(sig_name, item['uuid']))\n",
    "            return item['uuid']\n",
    "    \n",
    "    print(\"There is no instance group named {}\\nChoose one of these:\".format(sig_name))\n",
    "    for item in res:\n",
    "        print(item['name'])\n",
    "\n",
    "sigid = get_sigid(sig_name)\n",
    "\n",
    "#Construct dictionary that will create the sample datasets\n",
    "data = {\n",
    "  \"name\": dsname,\n",
    "  \"dbbackend\": \"TFRecords\",\n",
    "  \"trainpath\": trainpath,\n",
    "  \"sigid\": sigid,\n",
    "  \"imagedetail\": {\n",
    "        \"isusingtext\": \"false\",\n",
    "        \"trainimagepath\": trainpath,\n",
    "        \"imagetype\": \"Color\",\n",
    "        \"height\": 0,\n",
    "        \"width\": 0,\n",
    "        \"resizetransformation\": \"Squash\",\n",
    "        \"testpercentage\": 10,\n",
    "        \"splitalgorithm\": \"hold-out\"\n",
    "    },\n",
    "  \"byclass\": \"true\",\n",
    "  \"datasourcetype\": \"IMAGEFORCLASSIFICATION\"\n",
    "}\n",
    "print(\"\\n\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Get datasets or create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(dl_rest_url + '/datasets', auth=myauth, verify=False, headers=headers)\n",
    "res = json.loads(r.text)\n",
    "\n",
    "print(f'Found {len(res)} dataset/s')\n",
    "if len(res) > 0:\n",
    "    for item in res:\n",
    "        if item['status'] == 'FINISHED':\n",
    "            print(json.dumps(item, indent=4))\n",
    "        else:\n",
    "            print('Dataset not successfully finished\\n {}'.format(json.dumps(item, indent=4)))\n",
    "else:\n",
    "    print(\"Didn't find any dataset on server. Will create one...\\n\")\n",
    "    r = requests.post(url=dl_rest_url + '/datasets', auth=myauth, json=data, headers=headers, verify=False)\n",
    "    if r.ok is True:\n",
    "        print(\"Creating dataset, this might take about 2-3 minutes\")\n",
    "        while json.loads(requests.get(dl_rest_url + '/datasets', auth=myauth, verify=False, headers=headers).text)[0]['status'] != \"FINISHED\":\n",
    "            print(\"Creating\")\n",
    "            time.sleep(15)\n",
    "        print(\"Finished!\")\n",
    "    else:\n",
    "        print(\"Something went wrong!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Model Management: Modeltemplate -> Model -> Modeltraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Get modeltemplate or create it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"name\": \"resnet\",\n",
    "  \"path\": modelpath,\n",
    "  \"framework\": \"PyTorch\",\n",
    "}\n",
    "\n",
    "r = requests.get(dl_rest_url + '/modeltemplates', auth=myauth, verify=False, headers=headers)\n",
    "res = json.loads(r.text)\n",
    "\n",
    "if not res:\n",
    "    print(\"No modeltemplate found, will create one...\")\n",
    "    r = requests.post(url=dl_rest_url + '/modeltemplates', auth=myauth, json=data, headers=headers, verify=False)\n",
    "    if r.ok is True:\n",
    "        print(\"Modeltemplate created!\")\n",
    "    else:\n",
    "        print(\"Could not create model because:\\n\",r.text)\n",
    "else:\n",
    "    print(\"Found {} modeltemplate/s:\".format(len(res)))\n",
    "    for item in res:\n",
    "        print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.2 Get model or create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"name\": modelname,\n",
    "  \"templatename\": \"PyTorch-resnet\",\n",
    "  \"sig\": \"446d4bcc-da18-4695-8020-549f1baf3441\",\n",
    "  \"accelerator\": \"Single\",\n",
    "  \"hyperparameter\": {\n",
    "    \"learningrate\": 0.01,\n",
    "    \"momentum\": 0.0,\n",
    "    \"epoch\": 10,\n",
    "    \"weightdecay\": 0.0,\n",
    "    \"solvertype\": \"SGD\",\n",
    "    \"lrpolicy\": \"fixed\",\n",
    "    \"nesterov\": \"false\",\n",
    "    \"dampening\": 0.0\n",
    "  },\n",
    "  \"dataset\": \"CIFAR-10-MG\",\n",
    "  \"batchsize\": 32,\n",
    "  \"type\": \"Training\",\n",
    "}\n",
    "\n",
    "# There are tons of hyperparams which can be configured - see ref: https://<HOST>:9243/cloud/apis/explorer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(dl_rest_url + '/models', auth=myauth, verify=False, headers=headers)\n",
    "res = json.loads(r.text)\n",
    "\n",
    "if not res:\n",
    "    print(\"No model found, will create one...\")\n",
    "    r = requests.post(url=dl_rest_url + '/models', auth=myauth, json=data, headers=headers, verify=False)\n",
    "    if r.ok is True:\n",
    "        print(\"Model created!\")\n",
    "    else:\n",
    "        print(\"Could not create model because:\\n\",r.text)\n",
    "else:\n",
    "    for item in res:\n",
    "        print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3 Get modeltraining info or start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"trainName\": \"resnet-10-mg1\",\n",
    "  \"dlFramework\": \"PyTorch\",\n",
    "  \"gpuRatio\": 1,\n",
    "  \"clusterSize\": 1,\n",
    "  \"testInterval\": 100,\n",
    "  \"testIteration\": 10,\n",
    "  \"syncMode\": \"SYNC\",\n",
    "  \"distribute\": \"false\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(dl_rest_url + '/models/' + modelname + '/trainings', auth=myauth, verify=False, headers=headers)\n",
    "res = json.loads(r.text)\n",
    "\n",
    "if not res:\n",
    "    print(\"No model training found, will create one...\")\n",
    "    r = requests.post(dl_rest_url + '/models/' + modelname + '/trainings', auth=myauth, json=data, headers=headers, verify=False)\n",
    "    if r.ok is True:\n",
    "        print(\"Model training started! Waiting for 10 seconds to initialize...\")\n",
    "        time.sleep(10) # Needs some seconds to initialize\n",
    "        r = requests.get(dl_rest_url + '/models/' + modelname + '/trainings', auth=myauth, verify=False, headers=headers)\n",
    "        res = json.loads((r.text))\n",
    "    else:\n",
    "        print(\"Could not start model training because:\\n\",r.text)\n",
    "else:\n",
    "    for item in res:\n",
    "        print(json.dumps(item, indent=2))\n",
    "\n",
    "#trainingsname = res[0]['trainingParameters']['trainName']\n",
    "appid = res[0]['trainingParameters']['appid']\n",
    "r = requests.get(dl_rest_url + '/scheduler/applications?applicationid='+appid, auth=myauth, verify=False, headers=headers)\n",
    "res = json.loads((r.text))\n",
    "executorid = res[0]['executors'][0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Monitor the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "def show_graph(iteration, train_acc, test_acc, train_loss, test_loss):\n",
    "    plt.figure(figsize=(20,4))\n",
    "\n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(iteration, train_acc, label='Train')\n",
    "    ax1.plot(iteration, test_acc, label='Test')\n",
    "    ax1.title.set_text('Accuracy vs Iteration curve')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel('Accuracy (%)')\n",
    "    #ax1.set_ylim([0, 1])\n",
    "\n",
    "    ax2 = plt.subplot(132)\n",
    "    ax2.plot(iteration, train_loss, label='Train')\n",
    "    ax2.plot(iteration, test_loss, label='Test')\n",
    "    ax2.title.set_text('Loss vs Iteration curve')\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    #ax2.set_ylim([0, 3])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def get_metrics():\n",
    "    url = sc_rest_url + '/instances/' + sigid + '/applications/' + appid + '/' + executorid + '/logs/stderr?lastlines=1000000'\n",
    "    txtHeader = {'Accept': 'text/plain'}\n",
    "    r = requests.get(url=url, auth=myauth, verify=False, headers=txtHeader)\n",
    "    #res = json.loads((r.text))\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    iteration = []\n",
    "    for item in r.text.split(\"\\n\"):\n",
    "        if \"train_acc\" in item.lower():\n",
    "            iteration.append(int(item.split(\" \")[1].split(\":\")[0]))\n",
    "            train_acc.append(round(float(item.split(\" \")[5]),4))\n",
    "        if \"test_acc\" in item.lower():\n",
    "            test_acc.append(round(float(item.split(\" \")[5]),4))\n",
    "        if \"train_loss\" in item.lower():\n",
    "            train_loss.append(round(float(item.split(\" \")[5]),4))\n",
    "        if \"test_loss\" in item.lower():\n",
    "            test_loss.append(round(float(item.split(\" \")[5]),4))\n",
    "    \n",
    "    return iteration, train_acc, test_acc, train_loss, test_loss\n",
    "    \n",
    "\n",
    "while json.loads(requests.get(dl_rest_url + '/models/' + modelname + '/trainings', auth=myauth, verify=False, headers=headers).text)[0]['trainingParameters']['status'] == \"RUNNING\":\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    iteration, train_acc, test_acc, train_loss, test_loss = get_metrics()\n",
    "    \n",
    "    r = requests.get(dl_rest_url + '/scheduler/applications?applicationid='+appid, auth=myauth, verify=False, headers=headers)\n",
    "    res = json.loads((r.text))[0]['apprunduration']\n",
    "    print(f\"Current runtime: {str(res)[:5]} minutes\\n\")\n",
    "    print(f\"Iteration:\\n{iteration}\\nTrain accuracy:\\n{train_acc}\\nTest accuracy:\\n{test_acc}\\nTrain loss:\\n{train_loss}\\nTest loss:\\n{test_loss}\\n\")\n",
    "\n",
    "    if len(train_acc) < 2 and len(test_acc) < 2 and len(train_loss) < 2 and len(test_loss) < 2:\n",
    "        print(\"Waiting until we've at least two values for each variable to plot the graphs...\")\n",
    "        print(\"With the sample configuration in this notebook this should take about 5 minutes on 1xV100 GPU\")\n",
    "    elif len(train_acc) == len(iteration) and len(test_acc) == len(iteration) and len(train_loss) == len(iteration) and len(test_loss) == len(iteration):\n",
    "        show_graph(iteration, train_acc, test_acc, train_loss, test_loss)\n",
    "    else:\n",
    "        cnt = min(len(iteration), len(train_acc), len(test_acc), len(train_loss), len(test_loss))\n",
    "        show_graph(iteration[:cnt], train_acc[:cnt], test_acc[:cnt], train_loss[:cnt], test_loss[:cnt])\n",
    "        \n",
    "    time.sleep(5)\n",
    "        \n",
    "if json.loads(requests.get(dl_rest_url + '/models/' + modelname + '/trainings', auth=myauth, verify=False, headers=headers).text)[0]['trainingParameters']['status'] == \"FINISHED\":\n",
    "    print(\"Training finished\")\n",
    "    iteration, train_acc, test_acc, train_loss, test_loss = get_metrics()\n",
    "    show_graph(iteration, train_acc, test_acc, train_loss, test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(dl_rest_url + '/models', auth=myauth, verify=False, headers=headers)\n",
    "res = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not res:\n",
    "    print(\"No model exist at all\")\n",
    "else:\n",
    "    for item in res:\n",
    "        print(item['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
